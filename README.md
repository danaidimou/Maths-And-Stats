# Maths-And-Stats Project

A cooking website wants to improve their product page. Up until now they have had a horizontal rail. A UX designer suggested having a vertical one.

The business problem we are trying to solve is figuring out whether the media rail change will affect the user engagement and potentially the sales. 
Improving the product page might be crucial for the company because it influences the user experience. By optimizing the page layout, the company can create a more enjoyable browsing experience, potentially increasing customer satisfaction, loyalty and revenue.
However, drawbacks could include the potential for information overload if too many items are displayed at once, or it might disrupt users accustomed to the horizontal layout. Balancing the presentation of information is important to ensure that the change will have a positive impact. 

The hypothesis we're testing concerns the impact of changing the media rail from horizontal to vertical on a cooking website’s product page. We're assuming that this change would increase the sales and customer engagement.   
The null hypothesis would be that there is no significant difference in user engagement or sales between the horizontal and vertical layouts.
The alternative hypothesis would be that the vertical media layout significantly affects user engagement compared to the horizontal one.
_______________________________________________________________________________________________________________________________________________________

An A/B test is an effective method for testing hypotheses because it allows for a controlled experiment comparing two versions to see which performs better on specific metrics. It provides clear, quantitative evidence on whether the new variant impacts user engagement or sales, making it a powerful tool for data-driven decision-making.

Another method that could’ve been used is customer surveys.

While A/B testing is an excellent tool for obtaining objective, quantitative data on user behavior in response to specific changes, it can be limited, focusing mainly on the impact of those changes without capturing broader user needs or preferences. On the other hand, customer surveys can provide rich qualitative insights that A/B testing might miss, offering a deeper understanding of user motivations, preferences, and feedback on a wide range of topics.

A/B testing allows for a controlled environment where external variables are minimized, giving a clear picture of direct impacts on user behavior or KPIs. However, this method can be time-consuming and expensive, requiring the right tools and expertise to get meaningful results. In contrast, customer surveys are typically quicker and more cost-effective to deploy, although they come with their own set of challenges such as potential response bias and the complexity of interpreting qualitative data.

One of the key advantages of A/B testing is that it's enabling the collection of statistically significant data from a large number of users. Yet, the insights gained are generally limited to the specific variations being tested. Customer surveys, while offering direct feedback from users and the ability to explore a broader range of questions, may lack subjectivity in responses and lower response rates, which can affect the reliability of the data collected.

So while A/B testing provides precise insights into how changes affect user behavior, it lacks the depth of user understanding that surveys can provide. Surveys, despite their broader scope and direct user feedback capabilities, have issues of subjectivity and potential biases. The choice between the two methods —or the decision to use them both— depends on the specific goals, context, and resources available for your research or data collection.
______________________________________________________________________________________________________________________________________________________

As a primary metric, I chose the GMV($) because it directly reflects revenue, which is often the ultimate goal of any business. An increase in GMV would indicate that the variant being tested leads to higher sales. 
Another metric that I would wish to have, would be a Customer Satisfaction Score (CSAT). This metric could provide insights into how users perceive their experience beyond just their actions. High engagement and sales are valuable, but understanding user satisfaction can help predict long-term success.

